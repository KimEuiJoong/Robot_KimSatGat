{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['선생', '서덕출', '나', '학교', '조그마한', '학생', '집', '와', '선', '두', '말', '없이', '선생', '다', '우리', '동무', '두', '서넛', '다려다', '놓고', '가르치는', '선생', '다'], ['월', '노래', '짓밟힌', '무리', '흘린', '핏', '방울', '방울', '지심', '흘러', '흘러', '폭발', '되어', '새', '화산', '새', '세기', '화산', '솟았다', '북방', '높이', '솟은', '새', '히말라야', '산', '소비에트', '공화국', '그', '앞', '낡은', '제도', '골짜기', '무너졌다', '온', '세계', '바다', '끓는다', '오', '우리', '모국', '소비에트', '공화국', '거룩한', '탄생', '자라나가는', '우리', '힘', '억척스러운', '걸음', '걸음', '열네', '해', '맞는', '이', '날', '아침', '맑은', '햇빛', '아래', '더', '높이', '날려라', '붉은', '깃발', '더', '높이', '울려라', '승리', '쇠북', '만국', '승냥이', '이', '갈며', '떤다', '떤다', '사자', '새', '화산', '아들', '건장한', '무리', '원수', '향', '하여', '소리쳐라', '동무', '불러', '소리쳐라', '더', '한층', '높이', '쳐라', '만세', '만세', '우리', '손', '망치', '잡았고', '우리', '발', '바퀴', '굴', '린다', '우리', '어깨', '총', '메', '있고', '우리', '머리', '위엔', '새', '태양', '함께', '과학', '빛난다', '리하', '우리', '건설', '쉬일', '날', '없고', '우리', '무장', '원수', '물리치고야', '만다', '망치', '더', '힘', '있게', '내려', '쳐라', '바퀴', '더', '빨리', '굴러라', '태양', '더', '빛나게', '내리', '쪼여라', '우리', '걸음', '한', '시가', '급하고', '우리', '팔다리', '힘줄', '뛴다', '오직', '앞', '앞']]\n",
      "0        순수\n",
      "1        의지\n",
      "2        무심\n",
      "4        의지\n",
      "6        불안\n",
      "       ... \n",
      "4808     무심\n",
      "4835    즐거움\n",
      "4851     기쁨\n",
      "4852     희망\n",
      "4864     성찰\n",
      "Name: tags, Length: 1092, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#1.1\n",
    "#시, 태그 데이터 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "with open('C:\\DeepLearing\\Robot_KSG\\Softmax_Regression\\poems_token_MLP_v2', 'rb') as fr:\n",
    "    poems_token = pickle.load(fr)\n",
    "with open('C:\\DeepLearing\\Robot_KSG\\Softmax_Regression\\poems_tag', 'rb') as fr:\n",
    "    poems_tag = pickle.load(fr)\n",
    "\n",
    "print(poems_token[:2])\n",
    "print(poems_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기쁨#활기'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_tag[858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(poems_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830      [그리움2]\n",
       "831        [슬픔]\n",
       "832        [잔잔]\n",
       "833        [슬픔]\n",
       "834    [슬픔, 의지]\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_tag.str.split('#')[120:125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "#멀티 레이블 정제(#이용해 리스트로 변환) \n",
    "poems_tag = poems_tag.drop(poems_tag[poems_tag=='불용'].index)\n",
    "poems_tag = poems_tag.str.split('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['고독', '그리움1', '그리움2', '기쁨', '무심', '불안', '사랑1', '사랑2', '성찰', '순수',\n",
       "       '슬픔', '의지', '잔잔', '즐거움', '활기', '희망'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.3\n",
    "#레이블 이진화(벡터화)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "poems_tagVector = mlb.fit_transform(poems_tag)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_tagVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_tag.index[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>선생, 서덕출, 나, 학교, 조그마한, 학생, 집, 와, 선, 두, 말, 없이, 선...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>월, 노래, 짓밟힌, 무리, 흘린, 핏, 방울, 방울, 지심, 흘러, 흘러, 폭발,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일간, 깨끗한, 시트, 위, 나, 몸부림, 쳐도, 소용, 없다, 공간, 들려오는, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김창술, 울, 엉, 찬, 새벽, 고동, 잠들은, 이을, 흔들어, 우, 멀거, 케눈,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>년, 만가, 불안한, 언덕, 위, 나, 바람, 날려, 간다, 나, 죽어, 간다, 아...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem  \\\n",
       "0  선생, 서덕출, 나, 학교, 조그마한, 학생, 집, 와, 선, 두, 말, 없이, 선...   \n",
       "1  월, 노래, 짓밟힌, 무리, 흘린, 핏, 방울, 방울, 지심, 흘러, 흘러, 폭발,...   \n",
       "2  일간, 깨끗한, 시트, 위, 나, 몸부림, 쳐도, 소용, 없다, 공간, 들려오는, ...   \n",
       "4  김창술, 울, 엉, 찬, 새벽, 고동, 잠들은, 이을, 흔들어, 우, 멀거, 케눈,...   \n",
       "6  년, 만가, 불안한, 언덕, 위, 나, 바람, 날려, 간다, 나, 죽어, 간다, 아...   \n",
       "\n",
       "                                                tag  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "6  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.4\n",
    "#DataFrame으로 합치기(데이터 정제 + 머신러닝 전 데이터 분석용)\n",
    "poems_tokens = []\n",
    "for poem in poems_token:\n",
    "    poems_tokens.append(str(poem).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\"))\n",
    "\n",
    "poem_tag = pd.DataFrame(poems_tokens, columns = ['poem'])\n",
    "poem_tag['tag'] = pd.Series(poems_tag) #tag열 임시 추가\n",
    "poem_tag.dropna(axis=0, inplace=True) #태그 없는 데이터 제거\n",
    "\n",
    "for index in range(len(poems_tag.index)): \n",
    "    #index: 시의 인덱스를 찾기 위한 인덱스, 동시에 멀티 레이블의 인덱스(0~태그 개수 까지 반복)\n",
    "\n",
    "    poem_tag.loc[poems_tag.index[index], \"tag\"] = poems_tagVector[index]\n",
    "    #poems_tag.index[index] : 태그한 시의 인덱스\n",
    "    #poems_tagVector[index]: 위 시에 해당하는 태그 레이블\n",
    "\n",
    "poem_tag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    4,    6,    7,    8,   11,   13,   14,\n",
       "            ...\n",
       "            4702, 4720, 4729, 4730, 4741, 4808, 4835, 4851, 4852, 4864],\n",
       "           dtype='int64', length=440)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_tag.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_tag.loc[poem_tag.index[0], \"tag\"] = [0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 978 entries, 0 to 4864\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   poem    978 non-null    object\n",
      " 1   tag     978 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 62.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#정보 확인\n",
    "poem_tag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108.,  94.,  87.,  43.,  68.,  56.,  78.,  46.,  85., 104., 167.,\n",
       "        95., 133.,  48.,  76.,  58.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#그래프 그리려고 각 레이블별로 주제 세기\n",
    "import numpy as np\n",
    "tag_sum = np.zeros((16,))\n",
    "for tagVector in poem_tag['tag']:\n",
    "    tag_sum += tagVector\n",
    "\n",
    "tag_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['고독', '그리움1', '그리움2', '기쁨', '무심', '불안', '사랑1', '사랑2', '성찰', '순수',\n",
       "       '슬픔', '의지', '잔잔', '즐거움', '활기', '희망'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAATYklEQVR4nO3df6xf9X3f8edrOJBAmmHqa+bY3kwih4VEWYLuGG02lNXNQkOEyTYko6byViprE2mTbllqhhRaTUj0x/pD2pLJCzReS0EeIYUlaorrNmWTFtjlV7BxCG4hYDD2TVGbLplIDO/98T3evr1cc+8953uN+fj5kL76fs/nnPP+vn39/b7uued7zvmmqpAkteWvvdoNSJImz3CXpAYZ7pLUIMNdkhpkuEtSg1a82g0ArFq1qjZs2PBqtyFJryn333//t6pqar55J0W4b9iwgZmZmVe7DUl6TUnyzePNc7eMJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ16KQ4Q1VSfxu2f2nQ+k/eeNmEOtHJxC13SWqQ4S5JDTLcJalBhrskNWjBcE9yc5IjSfbOGf/pJI8l2Zfkl8bGr01yoJv3geVoWpL0yhZztMzngP8A/JdjA0n+IbAZeFdVvZBkdTd+AbAFeAfwZuAPkrytql6cdOOSpONbcMu9qu4Bnp8z/C+BG6vqhW6ZI934ZuC2qnqhqp4ADgAXTbBfSdIi9N3n/jbgHyS5N8kfJ/m73fha4Omx5Q52Yy+TZFuSmSQzs7OzPduQJM2nb7ivAFYCFwP/BtiVJEDmWbbmK1BVO6pquqqmp6bm/QpASVJPfcP9IHBHjdwHvASs6sbXjy23Dnh2WIuSpKXqG+6/C/wIQJK3AacD3wLuArYkOSPJecBG4L4J9ClJWoIFj5ZJcivwPmBVkoPA9cDNwM3d4ZHfA7ZWVQH7kuwCHgWOAtd4pIwknXgLhntVXXWcWR85zvI3ADcMaUqSNIxnqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGrRguCe5OcmR7luX5s77RJJKsmps7NokB5I8luQDk25YkrSwxWy5fw64dO5gkvXA+4GnxsYuALYA7+jW+XSS0ybSqSRp0RYM96q6B3h+nlm/BnwSqLGxzcBtVfVCVT0BHAAumkSjkqTF67XPPcnlwDNV9fCcWWuBp8emD3Zj89XYlmQmyczs7GyfNiRJx7HkcE9yJnAd8Kn5Zs8zVvOMUVU7qmq6qqanpqaW2oYk6RWs6LHOW4HzgIeTAKwDHkhyEaMt9fVjy64Dnh3apCRpaZa85V5Vj1TV6qraUFUbGAX6hVX1HHAXsCXJGUnOAzYC9020Y0nSghZzKOStwP8Ezk9yMMnVx1u2qvYBu4BHgS8D11TVi5NqVpK0OAvulqmqqxaYv2HO9A3ADcPakiQN4RmqktQgw12SGmS4S1KD+hwKKUmLsmH7l3qv++SNl02wk1OPW+6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatBivonp5iRHkuwdG/vlJF9P8rUkX0hy9ti8a5McSPJYkg8sU9+SpFewmC33zwGXzhnbDbyzqt4FfAO4FiDJBcAW4B3dOp9OctrEupUkLcqC4V5V9wDPzxm7u6qOdpNfBdZ1jzcDt1XVC1X1BHAAuGiC/UqSFmES+9x/Evi97vFa4OmxeQe7sZdJsi3JTJKZ2dnZCbQhSTpmULgnuQ44CtxybGiexWq+datqR1VNV9X01NTUkDYkSXP0/iamJFuBDwGbqupYgB8E1o8ttg54tn97kqQ+em25J7kU+Dng8qr67tisu4AtSc5Ich6wEbhveJuSpKVYcMs9ya3A+4BVSQ4C1zM6OuYMYHcSgK9W1b+oqn1JdgGPMtpdc01VvbhczUuS5rdguFfVVfMM3/QKy98A3DCkKUnSMJ6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDep94bCTyYbtX+q97pM3XjbBTiTp5OCWuyQ1yHCXpAYZ7pLUIMNdkhrUxAeq0muNBwFoubnlLkkNWjDck9yc5EiSvWNj5yTZneTx7n7l2LxrkxxI8liSDyxX45Kk41vMlvvngEvnjG0H9lTVRmBPN02SC4AtwDu6dT6d5LSJdStJWpQFw72q7gGenzO8GdjZPd4JXDE2fltVvVBVTwAHgIsm06okabH67nM/t6oOAXT3q7vxtcDTY8sd7MZeJsm2JDNJZmZnZ3u2IUmaz6Q/UM08YzXfglW1o6qmq2p6ampqwm1I0qmtb7gfTrIGoLs/0o0fBNaPLbcOeLZ/e5KkPvqG+13A1u7xVuDOsfEtSc5Ich6wEbhvWIuSpKVa8CSmJLcC7wNWJTkIXA/cCOxKcjXwFHAlQFXtS7ILeBQ4ClxTVS8uU++SpONYMNyr6qrjzNp0nOVvAG4Y0pQkaRgvPyDp/xlyWQTw0ggnE8N9Dq/5IakFXltGkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CBPYlpGnhAl6dXilrskNcgtd2mR/EtMryVuuUtSgwx3SWrQoHBP8rNJ9iXZm+TWJK9Pck6S3Uke7+5XTqpZSdLi9A73JGuBnwGmq+qdwGnAFmA7sKeqNgJ7umlJ0gk0dLfMCuANSVYAZzL6MuzNwM5u/k7gioHPIUlaot7hXlXPAL/C6DtUDwF/UVV3A+dW1aFumUPA6kk0KklavCG7ZVYy2ko/D3gzcFaSjyxh/W1JZpLMzM7O9m1DkjSPIbtlfhR4oqpmq+r7wB3ADwOHk6wB6O6PzLdyVe2oqumqmp6amhrQhiRpriEnMT0FXJzkTOD/AJuAGeA7wFbgxu7+zqFN6tThFzRLk9E73Kvq3iS3Aw8AR4EHgR3AG4FdSa5m9Avgykk0KklavEGXH6iq64Hr5wy/wGgrXpL0KvHaMpJOOafC7j8vPyBJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkCcxnaL8smepbW65S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYNCvckZye5PcnXk+xP8kNJzkmyO8nj3f3KSTUrSVqcoVvuvwF8uar+NvB3gP3AdmBPVW0E9nTTkqQTqHe4J3kTcAlwE0BVfa+q/hzYDOzsFtsJXDGsRUnSUg3Zcn8LMAv8ZpIHk3w2yVnAuVV1CKC7Xz3fykm2JZlJMjM7OzugDUnSXEPCfQVwIfCZqnoP8B2WsAumqnZU1XRVTU9NTQ1oQ5I015BwPwgcrKp7u+nbGYX94SRrALr7I8NalCQtVe8Lh1XVc0meTnJ+VT0GbAIe7W5bgRu7+zsn0qkknYSGXIQPlu9CfEOvCvnTwC1JTgf+FPjnjP4a2JXkauAp4MqBzyFJWqJB4V5VDwHT88zaNKSuXlu8fLB08vEMVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatDQyw9I0gnhmdBL45a7JDXIcJekBrlbRs06WS/FKp0IbrlLUoMMd0lqkLtlXiPcxSBpKQZvuSc5LcmDSb7YTZ+TZHeSx7v7lcPblCQtxSR2y3wM2D82vR3YU1UbgT3dtCTpBBoU7knWAZcBnx0b3gzs7B7vBK4Y8hySpKUbuuX+68AngZfGxs6tqkMA3f3q+VZMsi3JTJKZ2dnZgW1Iksb1DvckHwKOVNX9fdavqh1VNV1V01NTU33bkCTNY8jRMu8FLk/yQeD1wJuS/DZwOMmaqjqUZA1wZBKNSpIWr/eWe1VdW1XrqmoDsAX4w6r6CHAXsLVbbCtw5+AuJUlLshwnMd0IvD/J48D7u2lJ0gk0kZOYquorwFe6x38GbJpEXUlSP15+QJIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoCFfkL0+yR8l2Z9kX5KPdePnJNmd5PHufuXk2pUkLcaQLfejwL+uqrcDFwPXJLkA2A7sqaqNwJ5uWpJ0Ag35guxDVfVA9/gvgf3AWmAzsLNbbCdwxcAeJUlLNJF97kk2AO8B7gXOrapDMPoFAKw+zjrbkswkmZmdnZ1EG5KkzuBwT/JG4PPAx6vq24tdr6p2VNV0VU1PTU0NbUOSNGZQuCd5HaNgv6Wq7uiGDydZ081fAxwZ1qIkaamGHC0T4CZgf1X96tisu4Ct3eOtwJ3925Mk9bFiwLrvBX4CeCTJQ93YvwVuBHYluRp4CrhyUIeSpCXrHe5V9T+AHGf2pr51JUnDeYaqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalByxbuSS5N8liSA0m2L9fzSJJeblnCPclpwH8Efgy4ALgqyQXL8VySpJdbri33i4ADVfWnVfU94DZg8zI9lyRpjlTV5Ism/xS4tKp+qpv+CeDvVdVHx5bZBmzrJs8HHpt4IyOrgG+dpPVOhVqTrncq1Jp0vVOh1qTrnay15vpbVTU134zeX5C9gPm+OPuv/Bapqh3AjmV6/v/fSDJTVdMnY71Todak650KtSZd71SoNel6J2utpViu3TIHgfVj0+uAZ5fpuSRJcyxXuP8vYGOS85KcDmwB7lqm55IkzbEsu2Wq6miSjwK/D5wG3FxV+5bjuRZh0rt+JlnvVKg16XqnQq1J1zsVak263slaa9GW5QNVSdKryzNUJalBhrskNajpcJ/UJRCS3JzkSJK9E+hpfZI/SrI/yb4kHxtY7/VJ7kvycFfvFybQ42lJHkzyxYF1nkzySJKHkswMrHV2ktuTfL372f3QgFrndz0du307yccH1PvZ7me/N8mtSV4/oNbHujr7+vQ032s1yTlJdid5vLtfOaDWlV1vLyVZ9OF9x6n1y93/59eSfCHJ2QNq/buuzkNJ7k7y5iG9jc37RJJKsmpAbz+f5Jmx19sHF9vbIFXV5I3RB7l/ArwFOB14GLigZ61LgAuBvRPoaw1wYff4B4Bv9O2rqxHgjd3j1wH3AhcP7PFfAb8DfHFgnSeBVRP6/9wJ/FT3+HTg7Am+Tp5jdDJIn/XXAk8Ab+imdwH/rGetdwJ7gTMZHezwB8DGJdZ42WsV+CVge/d4O/CLA2q9ndFJh18Bpgf29Y+AFd3jXxzY15vGHv8M8J+G9NaNr2d0UMg3F/s6Pk5vPw98YhKv16XcWt5yn9glEKrqHuD5STRVVYeq6oHu8V8C+xkFRN96VVX/u5t8XXfr/Sl5knXAZcBn+9aYtCRvYvSmuQmgqr5XVX8+ofKbgD+pqm8OqLECeEOSFYyCue85HW8HvlpV362qo8AfAx9eSoHjvFY3M/rlSHd/Rd9aVbW/qpZ8Nvlxat3d/TsBvsrofJi+tb49NnkWS3gPvML7+9eAT06o1gnXcrivBZ4emz7IgBBdDkk2AO9htLU9pM5pSR4CjgC7q2pIvV9n9IJ+aUhPnQLuTnJ/d7mJvt4CzAK/2e0u+mySsybQH4zOwbi178pV9QzwK8BTwCHgL6rq7p7l9gKXJPnBJGcCH+SvngzY17lVdajr9xCwegI1J+0ngd8bUiDJDUmeBn4c+NTAWpcDz1TVw0PqjPlot9vo5sXuFhuq5XBf8BIIr6YkbwQ+D3x8zlbHklXVi1X1bkZbPhcleWfPnj4EHKmq+4f0M+a9VXUho6uDXpPkkp51VjD6U/czVfUe4DuMdi8M0p1gdznwXwfUWMloy/g84M3AWUk+0qdWVe1ntHtiN/BlRrsSj77iSg1Ich2jf+ctQ+pU1XVVtb6r89GFln+Ffs4ErmPgL4gxnwHeCryb0QbAv59Q3VfUcriftJdASPI6RsF+S1XdMam63a6KrwCX9izxXuDyJE8y2o31I0l+e0A/z3b3R4AvMNpV1sdB4ODYXyS3Mwr7oX4MeKCqDg+o8aPAE1U1W1XfB+4Afrhvsaq6qaourKpLGP15//iA3o45nGQNQHd/ZAI1JyLJVuBDwI9Xt4N6An4H+CcD1n8ro1/WD3fvhXXAA0n+Rp9iVXW42wB7CfjP9H8fLEnL4X5SXgIhSRjtO95fVb86gXpTx44ySPIGRmHz9T61quraqlpXVRsY/bz+sKp6bYUmOSvJDxx7zOjDs15HG1XVc8DTSc7vhjYBj/apNcdVDNgl03kKuDjJmd3/7SZGn6P0kmR1d/83gX88gf5g9Lrf2j3eCtw5gZqDJbkU+Dng8qr67sBaG8cmL6fnewCgqh6pqtVVtaF7LxxkdBDEcz17WzM2+WF6vg+W7ER/gnsib4z2WX6D0VEz1w2ocyujP6e+z+g/+uoBtf4+o91DXwMe6m4fHFDvXcCDXb29wKcm9LN7HwOOlmG0n/zh7rZvyM+/q/duYKb7d/4usHJgvTOBPwP++gR+Vr/AKEz2Ar8FnDGg1n9n9IvrYWBTj/Vf9loFfhDYw+ivgD3AOQNqfbh7/AJwGPj9AbUOMPpc7Nj7YFFHuByn1ue7n//XgP8GrB3yM5sz/0kWf7TMfL39FvBI19tdwJqhr7nF3Lz8gCQ1qOXdMpJ0yjLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoP+L9KdUrJnQeaPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#그래프 그려보기\n",
    "x = [i for i in range(16)]\n",
    "plt.xticks(x)\n",
    "plt.bar(x,tag_sum)\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "#훈련 데이터 / 테스트 데이터 분류\n",
    "sep_len = (int)(len(poem_tag)*8/10)\n",
    "\n",
    "train_poem = poem_tag['poem'].iloc[0:sep_len+1]\n",
    "train_tag = poem_tag['tag'].iloc[0:sep_len+1]\n",
    "test_poem = poem_tag['poem'].iloc[sep_len+1:len(poem_tag)+1]\n",
    "test_tag = poem_tag['tag'].iloc[sep_len+1:len(poem_tag)+1]\n",
    "\n",
    "max_words = 7000 #빈도수 정렬\n",
    "num_tag = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poem_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (353, 7000)\n",
      "훈련 샘플 레이블의 크기 : (353, 16)\n",
      "테스트 샘플 본문의 크기 : (87, 7000)\n",
      "테스트 샘플 레이블의 크기 : (87, 16)\n",
      "빈도수 상위 1위 단어 : 나\n",
      "빈도수 상위 1위 단어 : 실리어\n"
     ]
    }
   ],
   "source": [
    "#2.2\n",
    "#Keras Tokenizer로 DTM 생성(4가지 모드 사용 가능)\n",
    "def prepare_data(train_data, test_data, mode):\n",
    "    t = Tokenizer(num_words = max_words)\n",
    "    t.fit_on_texts(train_data)\n",
    "    X_train = t.texts_to_matrix(train_data, mode=mode)\n",
    "    X_test = t.texts_to_matrix(test_data, mode=mode)\n",
    "    \n",
    "    return X_train, X_test, t.index_word, mode\n",
    "\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "\n",
    "X_train, X_test, index_to_word, mode = prepare_data(train_poem, test_poem, modes[0])\n",
    "\n",
    "Y_train = np.array([np.asarray(np.zeros(16,)).astype(np.float32)]) #더미 ndarray 생성\n",
    "for y in train_tag.to_numpy():\n",
    "    Y_train = np.append(Y_train, np.array([np.asarray(y).astype(np.float32)]), axis=0)\n",
    "Y_train = np.delete(Y_train, 0, axis=0)\n",
    "Y_test = np.array([np.asarray(np.zeros(16,)).astype(np.float32)]) #더미 ndarray 생성\n",
    "for y in test_tag.to_numpy():\n",
    "    Y_test = np.append(Y_test, np.array([np.asarray(y).astype(np.float32)]), axis=0)\n",
    "Y_test = np.delete(Y_test, 0, axis=0)\n",
    "\n",
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(Y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(Y_test.shape))\n",
    "print(\"빈도수 상위 1위 단어 : {}\" .format(index_to_word[1]))\n",
    "print(\"빈도수 상위 1위 단어 : {}\" .format(index_to_word[max_words-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2244    [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
       "2252    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tag[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag.to_numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tag.to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_tag.to_numpy()[0]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_tag.to_numpy()[0]).astype(np.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndarr = np.array([[0,0,0]])\n",
    "ndarr = np.append(ndarr, [[0,0,2], [0,0,3]], axis=0)\n",
    "ndarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndarr = np.array([np.zeros(16,)])\n",
    "ndarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndarr = np.array([np.asarray(np.zeros(16,)).astype(np.float32)])\n",
    "ndarr = np.append(ndarr, np.array([np.asarray(train_tag.to_numpy()[0]).astype(np.float32)]), axis=0)\n",
    "\n",
    "ndarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_tag.to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.asarray(train_tag.to_numpy()[0]).astype(np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7000) <dtype: 'float32'>\n",
      "(None, 1) <dtype: 'float32'>\n",
      "dense_32 (None, 7000) float32\n",
      "dropout_20 (None, 128) float32\n",
      "dense_33 (None, 128) float32\n",
      "dropout_21 (None, 16) float32\n",
      "dense_34 (None, 16) float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 317 samples, validate on 36 samples\n",
      "Epoch 1/100\n",
      "317/317 [==============================] - 1s 2ms/sample - loss: 0.6704 - accuracy: 0.6268 - val_loss: 0.6314 - val_accuracy: 0.8142\n",
      "Epoch 2/100\n",
      "317/317 [==============================] - 0s 284us/sample - loss: 0.6004 - accuracy: 0.8119 - val_loss: 0.5751 - val_accuracy: 0.8733\n",
      "Epoch 3/100\n",
      "317/317 [==============================] - 0s 278us/sample - loss: 0.5363 - accuracy: 0.8665 - val_loss: 0.5185 - val_accuracy: 0.9010\n",
      "Epoch 4/100\n",
      "317/317 [==============================] - 0s 271us/sample - loss: 0.4684 - accuracy: 0.9012 - val_loss: 0.4664 - val_accuracy: 0.9167\n",
      "Epoch 5/100\n",
      "317/317 [==============================] - 0s 281us/sample - loss: 0.4218 - accuracy: 0.9158 - val_loss: 0.4219 - val_accuracy: 0.9201\n",
      "Epoch 6/100\n",
      "317/317 [==============================] - 0s 290us/sample - loss: 0.3665 - accuracy: 0.9257 - val_loss: 0.3871 - val_accuracy: 0.9201\n",
      "Epoch 7/100\n",
      "317/317 [==============================] - 0s 274us/sample - loss: 0.3286 - accuracy: 0.9272 - val_loss: 0.3617 - val_accuracy: 0.9201\n",
      "Epoch 8/100\n",
      "317/317 [==============================] - 0s 284us/sample - loss: 0.2989 - accuracy: 0.9294 - val_loss: 0.3451 - val_accuracy: 0.9201\n",
      "Epoch 9/100\n",
      "317/317 [==============================] - 0s 306us/sample - loss: 0.2680 - accuracy: 0.9326 - val_loss: 0.3354 - val_accuracy: 0.9201\n",
      "Epoch 10/100\n",
      "317/317 [==============================] - 0s 287us/sample - loss: 0.2549 - accuracy: 0.9357 - val_loss: 0.3304 - val_accuracy: 0.9201\n",
      "Epoch 11/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.2317 - accuracy: 0.9351 - val_loss: 0.3286 - val_accuracy: 0.9201\n",
      "Epoch 12/100\n",
      "317/317 [==============================] - 0s 309us/sample - loss: 0.2119 - accuracy: 0.9383 - val_loss: 0.3283 - val_accuracy: 0.9201\n",
      "Epoch 13/100\n",
      "317/317 [==============================] - 0s 297us/sample - loss: 0.2020 - accuracy: 0.9409 - val_loss: 0.3288 - val_accuracy: 0.9201\n",
      "Epoch 14/100\n",
      "317/317 [==============================] - 0s 274us/sample - loss: 0.1896 - accuracy: 0.9407 - val_loss: 0.3294 - val_accuracy: 0.9201\n",
      "Epoch 15/100\n",
      "317/317 [==============================] - 0s 306us/sample - loss: 0.1746 - accuracy: 0.9446 - val_loss: 0.3299 - val_accuracy: 0.9201\n",
      "Epoch 16/100\n",
      "317/317 [==============================] - 0s 287us/sample - loss: 0.1673 - accuracy: 0.9478 - val_loss: 0.3303 - val_accuracy: 0.9201\n",
      "Epoch 17/100\n",
      "317/317 [==============================] - 0s 306us/sample - loss: 0.1583 - accuracy: 0.9499 - val_loss: 0.3303 - val_accuracy: 0.9201\n",
      "Epoch 18/100\n",
      "317/317 [==============================] - 0s 246us/sample - loss: 0.1465 - accuracy: 0.9519 - val_loss: 0.3303 - val_accuracy: 0.9201\n",
      "Epoch 19/100\n",
      "317/317 [==============================] - 0s 300us/sample - loss: 0.1364 - accuracy: 0.9564 - val_loss: 0.3303 - val_accuracy: 0.9201\n",
      "Epoch 20/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.1289 - accuracy: 0.9592 - val_loss: 0.3301 - val_accuracy: 0.9201\n",
      "Epoch 21/100\n",
      "317/317 [==============================] - 0s 369us/sample - loss: 0.1241 - accuracy: 0.9612 - val_loss: 0.3301 - val_accuracy: 0.9201\n",
      "Epoch 22/100\n",
      "317/317 [==============================] - 0s 404us/sample - loss: 0.1166 - accuracy: 0.9641 - val_loss: 0.3300 - val_accuracy: 0.9201\n",
      "Epoch 23/100\n",
      "317/317 [==============================] - 0s 325us/sample - loss: 0.1105 - accuracy: 0.9671 - val_loss: 0.3298 - val_accuracy: 0.9201\n",
      "Epoch 24/100\n",
      "317/317 [==============================] - 0s 303us/sample - loss: 0.1076 - accuracy: 0.9683 - val_loss: 0.3300 - val_accuracy: 0.9201\n",
      "Epoch 25/100\n",
      "317/317 [==============================] - 0s 246us/sample - loss: 0.0987 - accuracy: 0.9698 - val_loss: 0.3308 - val_accuracy: 0.9201\n",
      "Epoch 26/100\n",
      "317/317 [==============================] - 0s 303us/sample - loss: 0.0933 - accuracy: 0.9738 - val_loss: 0.3318 - val_accuracy: 0.9201\n",
      "Epoch 27/100\n",
      "317/317 [==============================] - 0s 284us/sample - loss: 0.0897 - accuracy: 0.9714 - val_loss: 0.3331 - val_accuracy: 0.9201\n",
      "Epoch 28/100\n",
      "317/317 [==============================] - 0s 322us/sample - loss: 0.0877 - accuracy: 0.9748 - val_loss: 0.3343 - val_accuracy: 0.9201\n",
      "Epoch 29/100\n",
      "317/317 [==============================] - 0s 325us/sample - loss: 0.0834 - accuracy: 0.9744 - val_loss: 0.3357 - val_accuracy: 0.9201\n",
      "Epoch 30/100\n",
      "317/317 [==============================] - 0s 281us/sample - loss: 0.0787 - accuracy: 0.9787 - val_loss: 0.3373 - val_accuracy: 0.9201\n",
      "Epoch 31/100\n",
      "317/317 [==============================] - 0s 334us/sample - loss: 0.0791 - accuracy: 0.9769 - val_loss: 0.3389 - val_accuracy: 0.9201\n",
      "Epoch 32/100\n",
      "317/317 [==============================] - 0s 319us/sample - loss: 0.0737 - accuracy: 0.9795 - val_loss: 0.3406 - val_accuracy: 0.9201\n",
      "Epoch 33/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0661 - accuracy: 0.9840 - val_loss: 0.3424 - val_accuracy: 0.9201\n",
      "Epoch 34/100\n",
      "317/317 [==============================] - 0s 319us/sample - loss: 0.0661 - accuracy: 0.9823 - val_loss: 0.3444 - val_accuracy: 0.9201\n",
      "Epoch 35/100\n",
      "317/317 [==============================] - 0s 309us/sample - loss: 0.0620 - accuracy: 0.9850 - val_loss: 0.3464 - val_accuracy: 0.9201\n",
      "Epoch 36/100\n",
      "317/317 [==============================] - 0s 284us/sample - loss: 0.0613 - accuracy: 0.9821 - val_loss: 0.3488 - val_accuracy: 0.9201\n",
      "Epoch 37/100\n",
      "317/317 [==============================] - 0s 295us/sample - loss: 0.0576 - accuracy: 0.9852 - val_loss: 0.3512 - val_accuracy: 0.9201\n",
      "Epoch 38/100\n",
      "317/317 [==============================] - 0s 293us/sample - loss: 0.0529 - accuracy: 0.9884 - val_loss: 0.3534 - val_accuracy: 0.9201\n",
      "Epoch 39/100\n",
      "317/317 [==============================] - 0s 274us/sample - loss: 0.0544 - accuracy: 0.9874 - val_loss: 0.3557 - val_accuracy: 0.9201\n",
      "Epoch 40/100\n",
      "317/317 [==============================] - 0s 268us/sample - loss: 0.0487 - accuracy: 0.9905 - val_loss: 0.3582 - val_accuracy: 0.9201\n",
      "Epoch 41/100\n",
      "317/317 [==============================] - 0s 301us/sample - loss: 0.0490 - accuracy: 0.9882 - val_loss: 0.3605 - val_accuracy: 0.9201\n",
      "Epoch 42/100\n",
      "317/317 [==============================] - 0s 313us/sample - loss: 0.0471 - accuracy: 0.9896 - val_loss: 0.3626 - val_accuracy: 0.9201\n",
      "Epoch 43/100\n",
      "317/317 [==============================] - 0s 284us/sample - loss: 0.0465 - accuracy: 0.9905 - val_loss: 0.3646 - val_accuracy: 0.9201\n",
      "Epoch 44/100\n",
      "317/317 [==============================] - 0s 287us/sample - loss: 0.0452 - accuracy: 0.9905 - val_loss: 0.3665 - val_accuracy: 0.9201\n",
      "Epoch 45/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0412 - accuracy: 0.9909 - val_loss: 0.3685 - val_accuracy: 0.9201\n",
      "Epoch 46/100\n",
      "317/317 [==============================] - 0s 259us/sample - loss: 0.0424 - accuracy: 0.9923 - val_loss: 0.3706 - val_accuracy: 0.9201\n",
      "Epoch 47/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.0402 - accuracy: 0.9925 - val_loss: 0.3725 - val_accuracy: 0.9201\n",
      "Epoch 48/100\n",
      "317/317 [==============================] - 0s 241us/sample - loss: 0.0370 - accuracy: 0.9935 - val_loss: 0.3744 - val_accuracy: 0.9201\n",
      "Epoch 49/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.0377 - accuracy: 0.9925 - val_loss: 0.3762 - val_accuracy: 0.9201\n",
      "Epoch 50/100\n",
      "317/317 [==============================] - 0s 249us/sample - loss: 0.0356 - accuracy: 0.9947 - val_loss: 0.3784 - val_accuracy: 0.9201\n",
      "Epoch 51/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0328 - accuracy: 0.9937 - val_loss: 0.3797 - val_accuracy: 0.9201\n",
      "Epoch 52/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0333 - accuracy: 0.9951 - val_loss: 0.3810 - val_accuracy: 0.9201\n",
      "Epoch 53/100\n",
      "317/317 [==============================] - 0s 259us/sample - loss: 0.0338 - accuracy: 0.9939 - val_loss: 0.3826 - val_accuracy: 0.9201\n",
      "Epoch 54/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0319 - accuracy: 0.9945 - val_loss: 0.3846 - val_accuracy: 0.9201\n",
      "Epoch 55/100\n",
      "317/317 [==============================] - 0s 247us/sample - loss: 0.0300 - accuracy: 0.9957 - val_loss: 0.3868 - val_accuracy: 0.9201\n",
      "Epoch 56/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0280 - accuracy: 0.9953 - val_loss: 0.3891 - val_accuracy: 0.9201\n",
      "Epoch 57/100\n",
      "317/317 [==============================] - 0s 249us/sample - loss: 0.0280 - accuracy: 0.9957 - val_loss: 0.3914 - val_accuracy: 0.9201\n",
      "Epoch 58/100\n",
      "317/317 [==============================] - 0s 253us/sample - loss: 0.0296 - accuracy: 0.9961 - val_loss: 0.3934 - val_accuracy: 0.9201\n",
      "Epoch 59/100\n",
      "317/317 [==============================] - 0s 238us/sample - loss: 0.0284 - accuracy: 0.9961 - val_loss: 0.3958 - val_accuracy: 0.9201\n",
      "Epoch 60/100\n",
      "317/317 [==============================] - 0s 250us/sample - loss: 0.0268 - accuracy: 0.9959 - val_loss: 0.3984 - val_accuracy: 0.9201\n",
      "Epoch 61/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0247 - accuracy: 0.9968 - val_loss: 0.4007 - val_accuracy: 0.9201\n",
      "Epoch 62/100\n",
      "317/317 [==============================] - 0s 252us/sample - loss: 0.0250 - accuracy: 0.9972 - val_loss: 0.4030 - val_accuracy: 0.9201\n",
      "Epoch 63/100\n",
      "317/317 [==============================] - 0s 306us/sample - loss: 0.0246 - accuracy: 0.9968 - val_loss: 0.4057 - val_accuracy: 0.9201\n",
      "Epoch 64/100\n",
      "317/317 [==============================] - 0s 309us/sample - loss: 0.0224 - accuracy: 0.9976 - val_loss: 0.4085 - val_accuracy: 0.9201\n",
      "Epoch 65/100\n",
      "317/317 [==============================] - 0s 271us/sample - loss: 0.0222 - accuracy: 0.9976 - val_loss: 0.4109 - val_accuracy: 0.9201\n",
      "Epoch 66/100\n",
      "317/317 [==============================] - 0s 261us/sample - loss: 0.0225 - accuracy: 0.9968 - val_loss: 0.4137 - val_accuracy: 0.9201\n",
      "Epoch 67/100\n",
      "317/317 [==============================] - 0s 286us/sample - loss: 0.0217 - accuracy: 0.9978 - val_loss: 0.4166 - val_accuracy: 0.9201\n",
      "Epoch 68/100\n",
      "317/317 [==============================] - 0s 271us/sample - loss: 0.0221 - accuracy: 0.9972 - val_loss: 0.4190 - val_accuracy: 0.9219\n",
      "Epoch 69/100\n",
      "317/317 [==============================] - 0s 278us/sample - loss: 0.0209 - accuracy: 0.9980 - val_loss: 0.4210 - val_accuracy: 0.9219\n",
      "Epoch 70/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.0193 - accuracy: 0.9980 - val_loss: 0.4226 - val_accuracy: 0.9219\n",
      "Epoch 71/100\n",
      "317/317 [==============================] - 0s 247us/sample - loss: 0.0186 - accuracy: 0.9980 - val_loss: 0.4242 - val_accuracy: 0.9219\n",
      "Epoch 72/100\n",
      "317/317 [==============================] - 0s 255us/sample - loss: 0.0193 - accuracy: 0.9974 - val_loss: 0.4257 - val_accuracy: 0.9219\n",
      "Epoch 73/100\n",
      "317/317 [==============================] - 0s 259us/sample - loss: 0.0183 - accuracy: 0.9978 - val_loss: 0.4271 - val_accuracy: 0.9219\n",
      "Epoch 74/100\n",
      "317/317 [==============================] - 0s 252us/sample - loss: 0.0175 - accuracy: 0.9980 - val_loss: 0.4286 - val_accuracy: 0.9219\n",
      "Epoch 75/100\n",
      "317/317 [==============================] - 0s 249us/sample - loss: 0.0184 - accuracy: 0.9974 - val_loss: 0.4304 - val_accuracy: 0.9219\n",
      "Epoch 76/100\n",
      "317/317 [==============================] - 0s 273us/sample - loss: 0.0180 - accuracy: 0.9978 - val_loss: 0.4320 - val_accuracy: 0.9219\n",
      "Epoch 77/100\n",
      "317/317 [==============================] - 0s 201us/sample - loss: 0.0177 - accuracy: 0.9982 - val_loss: 0.4336 - val_accuracy: 0.9219\n",
      "Epoch 78/100\n",
      "317/317 [==============================] - 0s 247us/sample - loss: 0.0175 - accuracy: 0.9988 - val_loss: 0.4355 - val_accuracy: 0.9219\n",
      "Epoch 79/100\n",
      "317/317 [==============================] - 0s 261us/sample - loss: 0.0166 - accuracy: 0.9990 - val_loss: 0.4377 - val_accuracy: 0.9219\n",
      "Epoch 80/100\n",
      "317/317 [==============================] - 0s 271us/sample - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.4397 - val_accuracy: 0.9219\n",
      "Epoch 81/100\n",
      "317/317 [==============================] - 0s 274us/sample - loss: 0.0155 - accuracy: 0.9986 - val_loss: 0.4415 - val_accuracy: 0.9219\n",
      "Epoch 82/100\n",
      "317/317 [==============================] - 0s 237us/sample - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.4430 - val_accuracy: 0.9219\n",
      "Epoch 83/100\n",
      "317/317 [==============================] - 0s 240us/sample - loss: 0.0150 - accuracy: 0.9994 - val_loss: 0.4448 - val_accuracy: 0.9219\n",
      "Epoch 84/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.0166 - accuracy: 0.9982 - val_loss: 0.4463 - val_accuracy: 0.9219\n",
      "Epoch 85/100\n",
      "317/317 [==============================] - 0s 268us/sample - loss: 0.0158 - accuracy: 0.9980 - val_loss: 0.4479 - val_accuracy: 0.9219\n",
      "Epoch 86/100\n",
      "317/317 [==============================] - 0s 246us/sample - loss: 0.0156 - accuracy: 0.9982 - val_loss: 0.4496 - val_accuracy: 0.9219\n",
      "Epoch 87/100\n",
      "317/317 [==============================] - 0s 240us/sample - loss: 0.0127 - accuracy: 0.9998 - val_loss: 0.4516 - val_accuracy: 0.9219\n",
      "Epoch 88/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.0142 - accuracy: 0.9986 - val_loss: 0.4535 - val_accuracy: 0.9219\n",
      "Epoch 89/100\n",
      "317/317 [==============================] - 0s 256us/sample - loss: 0.0134 - accuracy: 0.9994 - val_loss: 0.4555 - val_accuracy: 0.9219\n",
      "Epoch 90/100\n",
      "317/317 [==============================] - 0s 233us/sample - loss: 0.0125 - accuracy: 0.9992 - val_loss: 0.4575 - val_accuracy: 0.9219\n",
      "Epoch 91/100\n",
      "317/317 [==============================] - 0s 243us/sample - loss: 0.0133 - accuracy: 0.9990 - val_loss: 0.4596 - val_accuracy: 0.9219\n",
      "Epoch 92/100\n",
      "317/317 [==============================] - 0s 253us/sample - loss: 0.0133 - accuracy: 0.9994 - val_loss: 0.4614 - val_accuracy: 0.9219\n",
      "Epoch 93/100\n",
      "317/317 [==============================] - 0s 251us/sample - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.4628 - val_accuracy: 0.9219\n",
      "Epoch 94/100\n",
      "317/317 [==============================] - 0s 240us/sample - loss: 0.0116 - accuracy: 0.9994 - val_loss: 0.4644 - val_accuracy: 0.9219\n",
      "Epoch 95/100\n",
      "317/317 [==============================] - 0s 235us/sample - loss: 0.0132 - accuracy: 0.9986 - val_loss: 0.4660 - val_accuracy: 0.9219\n",
      "Epoch 96/100\n",
      "317/317 [==============================] - 0s 262us/sample - loss: 0.0116 - accuracy: 0.9994 - val_loss: 0.4675 - val_accuracy: 0.9219\n",
      "Epoch 97/100\n",
      "317/317 [==============================] - 0s 252us/sample - loss: 0.0107 - accuracy: 0.9996 - val_loss: 0.4679 - val_accuracy: 0.9219\n",
      "Epoch 98/100\n",
      "317/317 [==============================] - 0s 252us/sample - loss: 0.0104 - accuracy: 0.9992 - val_loss: 0.4686 - val_accuracy: 0.9219\n",
      "Epoch 99/100\n",
      "317/317 [==============================] - 0s 251us/sample - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.4699 - val_accuracy: 0.9219\n",
      "Epoch 100/100\n",
      "317/317 [==============================] - 0s 268us/sample - loss: 0.0098 - accuracy: 0.9998 - val_loss: 0.4713 - val_accuracy: 0.9219\n",
      "binary모드의 테스트 정확도: 0.9367816\n"
     ]
    }
   ],
   "source": [
    "#3.1\n",
    "#DeepLearning 모델 설계 + 학습 + 자체평가\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(16, activation='softmax'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units=16, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=100, verbose=1, validation_split=0.1)\n",
    "\n",
    "absoluteScore = model.evaluate(X_test, Y_test, batch_size=128, verbose=0)\n",
    "\n",
    "print(mode+\"모드의 테스트 정확도:\", absoluteScore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00055224 0.00264835 0.00346491 0.00222716 0.00582132 0.00095943\n",
      " 0.00083423 0.00208065 0.00132024 0.00621808 0.04912338 0.00777182\n",
      " 0.00136983 0.0010443  0.00154889 0.05875748]\n",
      "15 희망\n",
      "10 슬픔\n",
      "11 의지\n",
      "\n",
      "\n",
      "10 슬픔\n",
      "15 희망\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.2\n",
    "#새로운 input 데이터로 모델 평가\n",
    "def predict_tag(arr, n): #레이블(확률 배열)에서 상위값 n(태그 개수)개의 인덱스 반환 \n",
    "    arr_temp = arr.copy()\n",
    "    tag = []\n",
    "    for i in range(n):\n",
    "        tag.append(arr_temp.argmax()) #arr에서 제일 큰 값의 인덱스 tag라는 리스트에 추가\n",
    "        arr_temp[arr_temp.argmax()] = 0\n",
    "    return tag\n",
    "\n",
    "def predict_tag2(arr, r): #레이블(확률 배열)에서 r(점수)이상의 인덱스 반환 \n",
    "    arr_temp = arr.copy()\n",
    "    tag = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr_temp[i] > r:\n",
    "            tag.append(i) #arr에서 제일 큰 값의 인덱스 tag라는 리스트에 추가  \n",
    "    return tag\n",
    "\n",
    "Y_pred = model.predict(X_test, batch_size=1)\n",
    "\n",
    "print(Y_pred[0])\n",
    "for i in predict_tag(Y_pred[0], 3):\n",
    "    print(i, mlb.classes_[i])\n",
    "print(\"\\n\")\n",
    "for i in predict_tag2(Y_pred[0], 0.01):\n",
    "    print(i, mlb.classes_[i])\n",
    "print(\"\\n\")\n",
    "#for i in np.where((Y_test[0]==1))[0]:\n",
    "#   print(i, mlb.classes_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23187878727912903"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for p in Y_pred[0]:\n",
    "    sum_p += p\n",
    "sum_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 16)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "Y_pred2 = Y_pred.copy()\n",
    "Y_pred_bit = []\n",
    "for y_pred in Y_pred2:\n",
    "    for i in predict_tag(y_pred, 3):\n",
    "        y_pred[i] = 1\n",
    "    Y_pred_bit.append(y_pred.astype(int)) \n",
    "\n",
    "np.sum(np.sum(Y_test.astype(int) & Y_pred_bit, axis=1) > 0)/Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42528735632183906"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "Y_pred2 =  Y_pred.copy()\n",
    "Y_pred_bit = []\n",
    "for y_pred in Y_pred2:\n",
    "    for i in predict_tag2(y_pred, 0.01):\n",
    "        y_pred[i] = 1\n",
    "    Y_pred_bit.append(y_pred.astype(int)) \n",
    "\n",
    "np.sum(np.sum(Y_test.astype(int) & Y_pred_bit, axis=1) > 0)/Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_bit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(Y_test.astype(int) & Y_pred_bit, axis=1)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_test[0].astype(int) & Y_pred_bit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['고독', '그리움1', '그리움2', '기쁨', '무심', '불안', '사랑1', '사랑2', '성찰', '순수',\n",
       "       '슬픔', '의지', '잔잔', '즐거움', '활기', '희망'], dtype=object)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'불, 사, 루자, 노자, 영, 아, 빨간, 불, 던지라, 나, 몸, 위, 모두, 태워, 버리자, 나, 피, 나, 뼈, 나, 살, 전적, 자아, 모두, 태워, 버리자, 아, 강한, 불, 던지라, 나, 몸, 위, 모두, 태워, 버리자, 나, 몸, 붙어, 있는, 모든, 애착, 모든, 인습, 모든, 설움, 모든, 아픔, 전적, 자아, 모두, 태워, 버리자, 아, 횃불, 던지라, 나, 몸, 위, 모두, 태워, 버리자, 나, 몸, 숨겨, 있는, 모든, 거짓, 모든, 가면, 오, 그러면, 나, 불, 되리라, 타오르는, 불꽃, 되리라, 불로, 만든, 새로운, 자아, 살, 보리, 불, 타는, 불, 나, 영원히, 불, 살겠다, 모든, 것, 사, 루고, 모든, 것, 녹이는, 불, 살겠다, 백조'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poem.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2244    불, 사, 루자, 노자, 영, 아, 빨간, 불, 던지라, 나, 몸, 위, 모두, 태...\n",
       "2252    불꽃놀이, 서건우, 불꽃놀이, 캐논, 같, 애, 뻥뻥, 뻥, 심장, 울려, 형형색색...\n",
       "2292    비, 오는, 밤, 한숨, 무너진, 설움, 집, 혼자, 우는, 어, 두운, 밤, 또다...\n",
       "2296    비, 돌, 그늘, 차고, 따로, 몰리는, 소, 소리, 바람, 앞, 섰거니, 하야, ...\n",
       "2330    비애, 번민, 고통, 슬픔, 가슴속, 웅덩이, 움물, 판다, 눈물, 곳, 소사, 올...\n",
       "                              ...                        \n",
       "4808    황야, 의, 설야, 아득한, 황야, 밤눈, 나리, 원, 바람, 일어, 휘감아, 도,...\n",
       "4835    휘파람, 권태, 응, 늘, 듣는, 저, 곡조, 휘파람, 신나요, 공장, 간, 언니,...\n",
       "4851    희망, 꼬, 부러진, 소나무, 목련, 꽃, 훨쩍, 피었다, 붉은, 아침, 해가, 오...\n",
       "4852    희망, 날, 믈, 눈, 려, 낫, 서른, 물, 내가왓슬, 산, 속, 올, 뱀, 울고...\n",
       "4864    흰, 그림자, 황혼, 짙어지는, 길, 모금, 하루, 종일, 시들은, 귀, 가만히, ...\n",
       "Name: poem, Length: 87, dtype: object"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import SGD\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
